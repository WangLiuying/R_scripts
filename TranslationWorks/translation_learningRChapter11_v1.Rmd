---
title: "第十一章"
author: "Rclub"
date: "2017年2月16日"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#第十一章：数据库操控

在之前的章节中，你已学习了面向对象编程的基本概念。这些基本概念包括类和方法，以及在R中，它们是如何以方法派遣的方式、由类函数联系起来的。你也掌握了 S3、S4、RC 和 R6 的基本用法，包括如何定义类和类函数、对某个类实施特定方法。

既然我们已经基本阐述完毕 R 的重要特性，现在让我们进一步地讨论些更加贴近实战的话题吧。在本章中，我们将开始讨论怎样用 R 来操控数据库，这大概是许多数据分析项目的第一步：从数据库中提取数据。具体地，我们会涵盖以下话题：

* 了解关系型数据
* 使用 SQL 工具，例如 SQLite、MySQL，对关系型数据进行查询
* 操控非关系型数据库，如 MongoDB 和 Redis

##11.1操控关系型数据库

在前面的章节里，我们学习了一组内置函数，比如 read.csv 和 read.table，它们可用于从诸如 csv 格式的分隔符分隔值文件中读取数据。然而，当数据文件很大时，这些存储方式未必是种好方法。

为什么文本格式不再适用呢？主要有三个理由，如下：
 
1. read.csv( ) 这类函数主要用于将整个文件读取到内存中，成为 R 中的一个数据框。如果这个数据太大了，计算机内存无法适应，这个方法就失效了。

2. 纵然数据集很大，通常我们的任务并不需要我们将整个数据集载入内存。相反，我们往往只需根据某些条件，提取原数据集的一个子集。内置的数据读取函数并不能对 csv 文件进行查询工作。

3. 数据集在不断更新中，即我们需要定期地往数据集中添加记录。如果我们采用 csv 格式，写入数据的工作将会非常不便，尤其是当我们想在文件的中部插入新记录、又要保持其它记录的原有顺序时。

针对以上情形，最好的方案是使用数据库。它能有效应对超出计算机内存容量的数据存储问题。针对用户提供的条件，数据库数据是可查询的，这也使得在数据库中更新现有记录和增添新数据的操作变得简便。

一个关系型数据库就是由众多表格和表格间的关系组成的集合。数据库中的表和 R 中的数据框具有相同的形式。表格间可能存在关联，使得我们能轻松地合并多张表格的信息。

在这一节中，我们会从最简单的数据库开始讲解，SQLite(http://sqlite.org/)，一个轻量型的数据库引擎。

在 R 中操控 SQLite 数据库，我们会用到 RSQLite 程序包。运行下面的代码可以从 CRAN 上下载并安装此包：
```{r,eval=F}
install.packages("RSQLite")
```

###11.1.1创建一个 SQLite 数据库

首先，让我们来看看如何创建一个 SQLite 数据库。如果我们想要在创建一个示例数据库并使其路径为 data/example.sqlite，我们必须确保该路径存在。如果该路径不存在，必须先创建路径：
```{r}
if (!dir.exists("data")) dir.create("data")
```

现在，路径 data/ 是可访问的。接下来我们载入 RSQLite 程序包，为了与数据库文件（data/example.sqlite）建立连接，需要提供一个数据库驱动（SQLite( )）。尽管目标文件尚不存在，驱动会创建并连接至一个空 SQLite 数据库：
```{r,warning=FALSE}
library(RSQLite)
##装载相关程序包：DBI
con <- dbConnect(SQLite( ), "data/example.sqlite")
```

数据库连接 con 是用户和系统中间的一层。我们创建该连接至一个关系型数据库，并通过它实现查询、提取及更新数据。我们会在后续的操作中一直用到该连接，直到我们关闭连接。在一个典型的关系型数据库中，我们可以指定表的名字、指定列的名字和数据类型来创建新表，增添若干行记录到表中，也可以更新现有的记录。关系型数据中的一张表看起来非常像 R 里的数据框。

现在，我们将创建一个简单的数据框，并将它作为一张表格插入数据库。

```{r}
example1 <- data.frame(
  id=1:5,
  type=c("A", "A", "B", "B", "C"),
  score=c(8, 9, 8, 10, 9),
  stringsAsFactors = FALSE)
example1
```

数据框已经备好，我们将调用 dbWriteTable( ) 将它写入数据库中，作为库中的表：
```{r}
dbWriteTable(con, "example1", example1)
```

在前面的代码中，我们也可以指定其它表名来存储同样的数据。最终，我们用 dbDisconnect( ) 断开数据库连接，con 不再为后续的操作生效。

```{r}
dbDisconnect(con)
```

####1.向一个数据库写入多张表格

一个 SQLite 数据库是表格的集合。因此，我们可以在数据库中存储多张表。

这次，我们要将 ggplot2 中的 diamonds 数据集和 flights 中的 nycflights13 数据集作为两张表格写入一个数据库中。如果你还没有安装这两个包，运行下列代码：
```{r,eval=F}
install.packages(c("ggplot2", "nycflights13"))
```

安装好两个程序包，我们就可以调用 data( ) 来载入所需数据框：

```{r}
data("diamonds", package ="ggplot2")
data("flights", package ="nycflights13")
```

我们重复之前的操作，但 dbWriteTable( ) 报错：
```{r, error=TRUE}
con <- dbConnect(SQLite( ), "data/datasets.sqlite")
dbWriteTable(con, "diamonds", diamonds, row.names=FALSE)
dbWriteTable(con, "flights", flights, row.names=FALSE)
dbDisconnect(con)
```

检查以下这两个变量的类型，可能会有所帮助：

```{r}
class(diamonds)
class(flights)
```

注意， diamonds 和 flights 不仅仅是一般的 data.frame 类型，而是更复杂的东西。要将它们写入数据库，我们需要用 as.data.frame( ) 将它们转化成普通的数据框对象。

```{r}
con <- dbConnect(SQLite( ), "data/datasets.sqlite")
dbWriteTable(con, "diamonds", as.data.frame(diamonds), row.names=FALSE)
dbWriteTable(con, "flights", as.data.frame(flights), row.names=FALSE)
dbDisconnect(con)
```

####2.向表中添加数据

本节开头我们提到，向数据库的表中添加记录是非常容易的。这里有一个简单的例子，我们产生几个数据块，然后依次将它们附到数据库表格中：

```{r}
con <- dbConnect(SQLite( ), "data/example2.sqlite")
chunk_size <- 10
id <- 0
for(i in 1:6) {
  chunk <- data.frame(id = ((i-1L) * chunk_size):(i * chunk_size-1L),
                      type = LETTERS[[i]],
                      score =rbinom(chunk_size, 10, (10-i)/10),
                      stringsAsFactors = FALSE)
  dbWriteTable(con, "products", chunk,
               append = i > 1, row.names=FALSE)
}
dbDisconnect(con)
```

注意，每节代码都产生了一个数据框，包含一些定值数据和一些随机数。每一次，我们将这些数据记录写入 products 表。这个例子与之前那些的不同之处在于，当我们调用 dbWriteTable( ) 时，在第一次循环中我们令参数 append = FALSE，以便在数据库中创建表格，而接下来每次循环中我们令 append = TRUE 来拓展已有的表格。

###11.1.2访问表和表中的字段

一旦我们拥有了一个 SQLite 数据库，我们不仅可以访问存储于表中的数据，也可以访问一些元数据，比如，所有表的名字或一个表中的列。

我们连接至之前创建的 SQLite 数据库，以便演示：

```{r}
con <- dbConnect(SQLite( ), "data/datasets.sqlite")
```

我们可以调用 dbExistsTable( ) 来检测数据库中是否含有某表：

```{r}
dbExistsTable(con, "diamonds")
dbExistsTable(con, "mtcars")
```

由于我们之前只往 datasets.sqlite 写入了 diamonds 和 flights ，dbExistTable( ) 返回了相应值。与检测表的存在相对地，我们用 dbListTables( ) 列出数据库中所有存在的表：

```{r}
dbListTables(con)
```

对某个特定的表，我们也可以调用 dbListFields( ) 列出表中所有列（或字段）的名字：

```{r}
dbListFields(con, "diamonds")
```

与 dbWriteTable( ) 相反，dbReadTable( ) 能将整张表格读入一个数据框：

```{r}
db_diamonds <- dbReadTable(con, "diamonds")
dbDisconnect(con)
```

我们可以比较从数据库中读取的数据框 (db_diamonds) 和原有的版本 (diamonds)：

```{r}
head(db_diamonds, 3)
head(diamonds, 3)
```

两个数据框的数据看起来完全一样。然而，如果调用 identical( ) 比较它们，它们并不一致：

```{r}
identical(diamonds, db_diamonds)
```

为了发现不同之处，我们调用 str( ) 来揭示两个数据框的结构。首先，这是数据库中表的结构：

```{r}
str(db_diamonds)
```

接着，这是原始版本的结构：

```{r}
str(diamonds)
```

现在，我们能清晰地看出区别了。在原有版本中，cut、color 和 clarity 是有序因子变量，由含元数据（次序水平）的整数构成。矛盾在于，在数据库版本中，这些列被存储为文本格式。这个变动的产生，是由于 SQLite 不具有序因子的内置支持机制。因此，除了共有的数据类型（数值型、文本型、逻辑型等等），在往数据库中添加数据框时，R 特有的类型会被转化为 SQLite 支持的类型。

###11.1.3学习用 SQL 对关系型数据库进行查询

前面几节中，你已掌握了往 SQLite 数据库中写入数据的方法。在这一节，你将学习如何根据我们的需求，对这样一个数据库进行查询。我们会在接下来的例子中使用（之前创建的） data/datasets.sqlite。 

首先，我们需要向数据库建立连接：

```{r}
con <- dbConnect(SQLite( ), "data/datasets.sqlite")
dbListTables(con)
```

数据库里有两张表。我们用 select 语句来选中 diamonds 中的所有数据。这里，我们想要选择所有列（字段）。所以，我们将调用 dbGetQuery( ) ，将数据库连接 con 和查询语句作为参数输入：

```{r}
db_diamonds <- dbGetQuery(con,
                          "select * from diamonds")
head(db_diamonds, 3)
```

注意，* 代表所有字段（列）。如果我们只需要字段的一个子集，我们可以依次列出字段名：

```{r}
db_diamonds <- dbGetQuery(con,
                          "select carat, cut, color, clarity, 
                              depth, price
                            from diamonds")
head(db_diamonds, 3)
```

如果我们想要出现在数据中的所有不重复的值，我们可以用 select distinct。例如，下面的代码会返回 diamonds 表 cut 字段的所有不重复取值：
```{r}
dbGetQuery(con, "select distinct cut from diamonds")
```

注意，dbGetQuery( ) 总是返回一个数据框，即使有时返回值只有一列。为使返回值恢复成一个原子向量，只要从数据框中取出第一列：

```{r}
dbGetQuery(con, "select distinct clarity from diamonds")[[1]]
```

当我们用 select 选择查询的列时，原表中的列名可能不是我们想要的。这种情况下，我们可以用 A as B 的形式，得到名为 B 的列，列中数据与原表 A 列一致：

```{r}
db_diamonds <- dbGetQuery(con,
                          "select carat, price, clarity as clarity_level 
                          from diamonds")
head(db_diamonds, 3)
```

有时候，我们想要的值并非直接存储在数据库中，而是需要经过一些计算得出。这时，我们会用 A as B 语句，这里的 A 是现有列之间的算术运算式：

```{r,results='hide'}
db_diamonds <- dbGetQuery(con,
                          "select carat, price, x * y * z as size
                          from diamonds")
head(db_diamonds, 3)
```
```
## Error in sqliteSendQuery(con, statement, bind.data): error in statement:
no such column: size
```

假如要由现有列生成一个新列，同时由该新列生成另一个列，就像下面这个例子，我们该怎么办呢？

```{r,error=T}
db_diamonds <- dbGetQuery(con,
                          "select carat, price, x * y * z as size,
                          price / size as value_density
                          from diamonds")
```

上面的做法行不通。语句 A as B 中，A 必须由已存在的列组成。然而，如果我们坚持
这么做，可以用嵌套查询的办法，即，通过一个内嵌的 select 语句产生一个临时的表，再从临时表中选出所需列：

```{r}
db_diamonds <- dbGetQuery(con,
                          "select *, price / size as value_density from
                           (select carat, price, x * y * z as size 
                              from diamonds)")
head(db_diamonds, 3)
```

在这个案例中，当我们计算 price/size 时，size 在临时表中已存在。

接下来是数据库查询的重要部分，条件查询。我们使用 where 来说明查询结果应满足的条件。例如，我们可以选择 cut 值为 good 的钻石数据：

```{r}
good_diamonds <- dbGetQuery(con,
                            "select carat, cut, price from diamonds 
                            where cut = 'Good'")
head(good_diamonds, 3)
```

注意，cut 取值为 good 的记录只有很小的比重：

```{r}
nrow(good_diamonds) /nrow(diamonds)
```

如果我们想让查询同时满足多个条件，我们可以用 and 来连结这些条件。比如，我们选出 cut 为 Good 且 color 值为 E 的记录：

```{r}
good_e_diamonds <- dbGetQuery(con,
                              "select carat, cut, color, price 
                                  from diamonds
                                where cut = 'Good' and color = 'E'")
head(good_e_diamonds, 3)
nrow(good_e_diamonds) /nrow(diamonds)
```

相似的逻辑算子还有 or 和 not。
除了这些简单逻辑算子之外，给定一个集合，欲筛选出取值属于该集合的所有记录，可以用 in 来完成操作。例如，我们要选出 color 为 E 或 F 的记录：

```{r}
color_ef_diamonds <- dbGetQuery(con,
                                "select carat, cut, color, price 
                                  from diamonds
                                where color in ('E', 'F')")
nrow(color_ef_diamonds)
```

我们用下表验证该结果：

```{r}
table(diamonds$color)
```

使用 in 的时候，我们要先指定一个集合。与 in 类似地，between and 允许我们指定一个区间：

```{r}
some_price_diamonds <- dbGetQuery(con,
                                  "select carat, cut, color, price 
                                    from diamonds
                                  where price between 5000 and 5500")
nrow(some_price_diamonds) /nrow(diamonds)
```

实际上这个区间不一定得是数值型的。只要字段的数据类型是可比的，我们就可以指定一个区间。比如字符串型的列，我们可用 between 'string1' to 'string2' 语句，按照字典排列顺序来筛选记录。

针对字符串字段，还有一个有用的算子，like，它可以用来筛选具备某简单模式的字段。比如说，我们要选出表中，cut 变量的取值是以 Good 结尾的记录。它可以是 Good 或 Very Good。我们用 like '%Good'，这里的 % 符号可以通配任何字符串。

```{r}
good_cut_diamonds <- dbGetQuery(con,
                                "select carat, cut, color, price 
                                  from diamonds           
                                where cut like '%Good' ")
nrow(good_cut_diamonds) /nrow(diamonds)
```

数据库查询还有一个重要功能，按照规定字段重新排列数据。用 order by 实现这个功能。比如，我们检索所有记录的 carat 和 price 字段，但按照 price 字段升序排列：

```{r}
cheapest_diamonds <- dbGetQuery(con,
                                "select carat, price from diamonds
                                order by price")
```

如此，我们得到一个钻石数据的数据框，是按照由便宜到昂贵的顺序排列的：

```{r}
head(cheapest_diamonds)
```

指定排序字段时加一个 desc，就可以降序排列，因此我们得到一个排序完全相反的数据框：

```{r}
most_expensive_diamonds <- dbGetQuery(con,
                                      "select carat, price from diamonds
                                      order by price desc")
head(most_expensive_diamonds)
```

排列记录时，我们也可以指派多个字段。比如，以下结果首先按照 price 的升序排列，如果两条记录的 price 取值相等，carat 取值更大的会被放在前面：

```{r}
cheapest_diamonds <- dbGetQuery(con,
                                "select carat, price from diamonds
                                order by price, carat desc")
head(cheapest_diamonds)
```

就像 select，用于排序的列可以从已有列计算生成：

```{r}
dense_diamonds <- dbGetQuery(con,
                             "select carat, price, x * y * z as size 
                                from diamonds
                             order by carat /size desc")
head(dense_diamonds)
```

我们也可以同时使用 where 和 order by，得到一个排序的子集结果：

```{r}
head(dbGetQuery(con,
                "select carat, price from diamonds
                where cut = 'Ideal' and clarity = 'IF' and color = 'J'
                order by price"))
```

如果我们只关心头几行结果，我们可以用 limit 来限制取出的记录数：

```{r}
dbGetQuery(con,
           "select carat, price from diamonds
           order by carat desc limit 3")
```

除了字段选择、条件筛选、排序，我们还可以分组聚合（aggregate）记录。例如，我们可以计算每种颜色的记录数：

```{r}
dbGetQuery(con,
           "select color, count(*) as number from diamonds
           group by color")
```

对原数据调用 table( ) ，检验查询结果：

```{r}
table(diamonds$color)
```

除了计数，其它可用的聚合函数有 avg( )、max( )、min( ) 和 sum( )。例如，我们想计算不同透明度水平的平均价格：

```{r}
dbGetQuery(con,
           "select clarity, avg(price) as avg_price
           from diamonds
           group by clarity
           order by avg_price desc")
```

我们也可以检查一下，最低的5个价格水平下，能买到的最大克拉数是多少：

```{r}
dbGetQuery(con,
           "select price, max(carat) as max_carat
           from diamonds
           group by price
           order by price limit 5")
```

也可在一组中同时运行多个运算。下列代码计算了每个透明度水平下价格的区间和平均值：

```{r}
dbGetQuery(con,
           "select clarity,
           min(price) as min_price,
           max(price) as max_price,
           avg(price) as avg_price
           from diamonds
           group by clarity
           order by avg_price desc")
```

接下来的一个例子，考虑到越重的钻石越昂贵，计算了不同透明度水平下每克拉钻石的均价：

```{r}
dbGetQuery(con,
           "select clarity,
           sum(price * carat) / sum(carat) as wprice
           from diamonds
           group by clarity
           order by wprice desc")
```

就像我们能够指派两个以上的字段进行排序，这里我们也可以用多个字段进行分组。下列的代码计算了不同透明度水平和颜色种类下钻石的平均价格，并展示最昂贵的五种组合：

```{r}
dbGetQuery(con,
           "select clarity, color,
           avg(price) as avg_price
           from diamonds
           group by clarity, color
           order by avg_price desc
           limit 5")
```

关系型数据中，最能体现“关系”概念的运算，应该是表的连接（join），即，将若干表通过某些字段连接起来。比如，我们将创建一个新的数据框 diamond_selector，共有三条记录，包含字段 cut、color、clarity，后续我们将筛选出字段取值符合这三条记录的数据：

```{r}
diamond_selector <- data.frame(
  cut = c("Ideal", "Good", "Fair"),
  color = c("E", "I", "D"),
  clarity = c("VS1", "T1", "IF"),
  stringsAsFactors = FALSE
  )
diamond_selector
```

创建好数据框后，我们将它写入数据库，然后就可以连接 diamonds 表和 diamond_selector 表，来筛选想要的记录了：

```{r}
dbWriteTable(con, "diamond_selector", diamond_selector,
             row.names=FALSE, overwrite=TRUE)
```

通过连接子句（join-clause）声明相匹配的列:

```{r}
subset_diamonds <- dbGetQuery(con,
                              "select cut, color, clarity, carat, price
                              from diamonds
                              join diamond_selector using 
                                (cut, color, clarity)")
head(subset_diamonds)
```

总计，任意符合三个筛选条件其中之一的，只有很少一部分记录：

```{r}
nrow(subset_diamonds) /nrow(diamonds)
```

最后，不要忘记断开数据库连接，确保所有资源被正确释放：

```{r}
dbDisconnect(con)
```

在前面的例子中，我们只展示了 SQL 用于查询关系型数据库的基础用法（以 SQLite 为例）。实际上，SQL 远比我们演示的要丰富和强大。更多细节，请访问 http://www.w3schools.com/sql。

##11.1.3分块提取查询结果

在本节初始，我们提到使用关系型数据库的优势之一，是可以存储大量数据。通常，我们只提取出数据库的一个子集来进行研究。然而，有时候，我们需要检查的数据量还是超过了计算机内存容量。显然，我们不能把所有数据载入内存，而必须逐块处理数据。

绝大部分关系型数据支持逐块提取查询数据。在接下来的例子中，我们会用 dbSendQuery( ) 进行查询，而不是 dbGetQuery( )。然后，我们重复地从查询结果中提取出一块数据（几行记录），直到遍历查询结果。通过这种方式，我们可以逐块处理数据，而不需用到很大的工作内存。

```{r}
con <- dbConnect(SQLite( ), "data/datasets.sqlite")
res <- dbSendQuery(con,
                   "select carat, cut, color, price from diamonds
                   where cut = 'Ideal' and color = 'E' ")
while(!dbHasCompleted(res)){
  chunk <- dbFetch(res, 800)
  cat(nrow(chunk), "records fetched\n")
}
dbClearResult(res)
dbDisconnect(con)
```

实践中，数据库中可能有数十亿条记录。查询结果有可能达到千万条。如果你用 dbGetQuery( ) 一次性取出所有查询结果，你的内存可能吃不消。如果你的任务容许你分块处理数据，那么上述方法不失为一个好的选择。

###11.1.4出于一致性考虑的事务方法

现流行的关系型数据库，在确保数据一致性方面，都有很强的工作能力。当我们增添和更新数据时，我们是通过“事务”方法实现的。如果一个事务操作失败了，我们可以撤销事务，并回滚数据库，以保证数据的一致性。

下面的例子简单模拟了一次数据积聚过程，在这种过程中时常出现错误。假设我们需要积聚某些产品的数据，并将它存储到 data/products.sqlite。每一次有一块数据生成，我们需要将它附入数据库中的某表上。然而在每次迭代操作中，该进程都有20%的概率出错。

```{r,error=T}
set.seed(123)
con <- dbConnect(SQLite( ), "data/products.sqlite")
chunk_size <- 10
for( i in 1:6 ){
  cat("Processing chunk", i, "\n")
  if(runif(1) <= 0.2) stop("Data error")
  chunk <- data.frame(id = ((i - 1L) * chunk_size) : (i * chunk_size - 1L),
                      type = LETTERS[[i]],
                      score = rbinom(chunk_size, 10, (10 - i) /10),
                      stringsAsFactors = FALSE)
  dbWriteTable(con, "products", chunk, append = i > 1, row.names = FALSE)
}
```

这个积累过程在第5块数据处理时出错。接着，我们来计算以下表中的记录数：

```{r}
dbGetQuery(con, "select COUNT(*) from products")
dbDisconnect(con)
```

我们发现表中存储了一些记录。某些情形下，我们希望要么所有数据都被正确存储，要么没有任何数据被存入数据库。这两种情形都保证了数据库的一致性。而若只有一部分数据被存储时，就会产生新的问题。为了确保这种一系列的数据库变更能够以整体的形式成功或失败，我们在写入任何数据前都调用 dbBegin( )，待所有变更完成后，调用 dbCommit( )，如果这个过程中出现错误，就调用 dbRollback( )。

接下来的代码是上一个例子的增强版。我们用事务方法来确保：要么所有分块数据被正确写入数据库，要么不做任何变更。更确切地说，我们把数据写入过程放进 tryCatch 里。写入开始前，我们调用 dbBegin( ) 宣布事务开始。接着，在 tryCatch 中，我们会向数据库逐块地写入数据。若一切顺利进行，我们会用 dbCommit( ) 确认事务使之生效。如果过程中出现任何错误，error( ) 函数会发现错误的产生，发出警告，并调用 dbRollback( ) 回滚：

```{r}
set.seed(123)
file.remove("data/products.sqlite")
con <- dbConnect(SQLite( ), "data/products.sqlite")
chunk_size <- 10
dbBegin(con)
fes <- tryCatch({
  for( i in 1:6 ){
    cat("Processing chunk", i, "\n")
    if(runif(1) <= 0.2) stop("Data error")
    chunk <- data.frame(id = ((i - 1L) * chunk_size) : (i * chunk_size - 1L),
                      type = LETTERS[[i]],
                      score = rbinom(chunk_size, 10, (10 - i) /10),
                      stringsAsFactors = FALSE)
  dbWriteTable(con, "products", chunk, append = i > 1, row.names = FALSE)
  }
  dbCommit(con)
},error = function(e){
  warning("An error occurs: ", e, "\nRolling back", immediate. = TRUE)
  dbRollback(con)
})
```

我们看到，相同的错误又一次发生。但是，这一次，这个错误被发现了，事务操作取消，数据库回滚。我们再一次计算表 products 中的记录数以验证：

```
dbGetQuery(con, "select COUNT(*) from products")
## Error in sqliteSendQuery(con, statement, bind.data): error in statement:no such table: products
```
```{r}
dbDisconnect(con)
```

计数查询导致了一次错误，这也许令你惊奇。为什么不返回0值呢？如果我们仔细检查这个例子，就会明白，在我们第一次调用 dbWriteTable( ) 时，它创建了一个新表，并把第一块数据写入。换言之，表的创建这一动作被包括在事务中。所以，当我们回滚时，表的创建也被撤销了。由于在后续的查询中，名为 products 的表根本不存在，结果就产生了一个错误。如果我们创建表在前，开始事务在后，那么撤销该事务后进行计数查询，结果应该恰好等于事务开始前表中的记录数。

还有一个例子要求数据之间的强一致性，那就是转账账目。当我们从一个账户向另一个账户进行转账时，必须确保系统从一个账户取出金额，并向另一账户存入相等金额。这两个变动要么同时发生，要么都失败，以保证一致性。这可以利用关系型数据的事务方法轻松实现。

假设我们定义一个函数，来创建一个虚拟银行的 SQLite 数据库。我们会用dbSendQuery( ) 发送命令，以创建账户表（accounts）和交易表（transactions）：

```{r}
create_bank <- function(dbfile) {
  if(file.exists(dbfile)) file.remove(dbfile)
  con <- dbConnect(SQLite( ), dbfile)
  dbSendQuery(con,
              "create table accounts
              (name text primarykey key, balance real)")
  dbSendQuery(con,
              "create table transactions
              (time text, account_from text, account_to text, 
              value real)")
  con
}
```

这个 accounts 表具有两列：name 和 balance。transactions 表有四列：time、account_from、
account_to 和 value。第一张表存储了所有账户信息，第二张表存储历史交易信息。

我们同时定义了一个函数，用来创建账户，写入账户名和初始余额。这个函数用 insert into 向 accounts 表写入新记录：

```{r}
create_account <- function(con, name, balance){
  dbSendQuery(con,
              sprintf("insert into accounts (name, balance) 
                      values ('%s', %.2f)",
                      name, balance))
  TRUE
}
```

我们用 sprintf( ) 来产生之前的 SQL 语句。它适用于本地和个人用途，但对于网络应用来说通常不够安全，因为黑客很容易通过局部的表达式运行一些灾难性的语句，进而操控整个数据库。

接着，我们会定义一个转账函数。这个函数会检查取款账户和收款账户是否都存在，接着确保取款账户余额是否足够完成转账请求，一旦转账有效，它会更新两个账户的余额并向数据库中添加一条交易记录：

```{r}
transfer <- function(con, from, to, value){
  get_account <- function(name){
    account <- dbGetQuery(con,
                          sprintf("select * from accounts
                                  where name = '%s' ", name))
    if (nrow(account) == 0)
      stop(sprintf("Account '%s' does nor exist", name))
    account
  }
  account_from <- get_account(from)
  account_to <- get_account(to)
  if (account_from$balance < value) {
    stop(sprintf("Insufficient money to transter from '%s' ", from))}
  else {
    dbSendQuery(con,
                sprintf("update accounts set balance = %.2f
                        where name = '%s' ",
                        account_from$balance - value, from))
    dbSendQuery(con,
                sprintf("update accounts set balance = %.2f
                        where name = '%s' ",
                        account_to$balance + value, to))
    dbSendQuery(con,
                sprintf("insert into transactions (time, account_from, account_to, value)
                        values ('%s', '%s', '%s', %.2f)", 
                        format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
                        from, to, value))
  }
  TRUE
}
```

尽管我们已经考虑到取款账户余额不足的可能性，对此进行事前检查，但是仍有其它原因导致了转账操作的风险。因此，我们将实施 transfer( ) 的一种安全版本，利用事务方法，确保一旦转账中出现任何错误，可以对 transfer( ) 函数所做的更改进行撤销。

```{r}
safe_transfer <- function(con, ...) {
  dbBegin(con)
  tryCatch({
    transfer(con, ...)
    dbCommit(con)
  }, error = function(e) {
    message("An error occurs in the transaction. Rollback...")
    dbRollback(con)
    stop(e)
  })
}
```

实际上， safe_transfer( ) 是 transfer( ) 函数的一个封装器。它仅仅是将 transfer( ) 放进了 tryCatch( ) 的沙盘中。如果有错误发生，我们就调用 doRollback( ) 确保数据库的一致性。

在对这些函数进行测试前，我们还需要用以查看账户余额和历史交易信息的函数。

```{r}
get_balance <- function(con, name) {
  res <- dbGetQuery(con,
                    sprintf("select balance from accounts
                            where name = '%s'", name))
  res$balance
}
get_transactions <- function(con, from, to) {
    dbGetQuery(con,  sprintf( "select * from transactions
                              where account_from = '%s' and
                              account_to = '%s'",
                              from,  to))
}
```

现在，我们能进行些测试了。首先，我们会用 create_bank( ) 创建一个虚拟银行，它将返回一个指向数据库文件的 SQLite 连接。然后，我们会创建两个账户，并赋予初始余额。

```{r,warning=F}
con <- create_bank("data/bank.sqlite")
create_account(con, "David", 5000)
create_account(con, "Jenny", 6500)
get_balance(con, "David")
get_balance(con, "Jenny")
```

接着，我们会用 safe_transfer( )，从 David 的账户向 Jenny 的账户转账。

```{r,warning=F}
safe_transfer(con, "David", "Jenny", 1500)
get_balance(con, "David")
get_balance(con, "Jenny")
```

转账成功了，保证一致性的前提下两个账户的余额都被修改。现在，我们要再做一次转账。这一次，David 的账户余额不足，所以转账会出错、失败。

```{r,error=T}
safe_transfer(con, "David", "Jenny", 6500)
get_balance(con, "David")
get_balance(con, "Jenny")
```

这里的函数发现了错误，并对数据库进行回滚。两个账户的余额没有变动。现在，我们查询所有成功的交易记录：

```{r}
get_transactions(con, "David", "Jenny")
```

我们找到了第一次交易，但第二次失败的交易没有出现在数据库中。最后，一定要记得切断数据库连接：

```{r}
dbDisconnect(con)
```

###11.1.5将多个文件的数据存入一个数据库

当我们处理大数据文件时，我们常常在读写数据方面遇到许多问题。实际中可能出现两种极端情况。一种情况是，一个非常大的文本格式数据源，几乎不能载入内存。另一种则是，数据被分为小块存储在许多文件中，我们需费时将它们整合成一个数据框。

对于第一种情况，我们可以逐块读取数据，并逐块地将它们添加到数据库的某张表中。以下函数可用于此情形，指定一个输入文件、一个输出数据库、一个表名和一个数据块的容量，即可将一个大的数据源分块地存入数据库的表中。考虑到输入数据可能过大、无法载入内存，所以这个函数每次只会读取一块数据，将其写入数据库，因此，只需要很小的工作内存：

```{r}
chunk_rw <- function(input, output, table, chunk_size = 10000) {
  first_row <- read.csv(input, nrows = 1, header = TRUE)
  header <- colnames(first_row)
  n <- 0
  con <- dbConnect(SQLite(), output)
  on.exit(dbDisconnect(con))
  while (TRUE) {
    df <- read.csv(input,
      skip = 1 + n * chunk_size,
      nrows = chunk_size,
      header = FALSE,
      col.names = header,
      stringsAsFactors = FALSE)
    if (nrow(df) == 0) break
    dbWriteTable(con, table, df, row.names = FALSE, append = n > 0)
    n <- n + 1
    cat(sprintf("%d records written\n", nrow(df)))
  }
}
```

这里的小诀窍是正确地计算输入文件里每个数据块的位移。

为了测试这个函数，我们先要将 diamonds 写入一个 csv 文件，再用 chunk_rw( ) 逐块地将 csv 文件写入 SQLite 数据库。用这种办法，写入过程只需要一个非常小的工作内存，远远小于将整个数据载入内存的方法。

```{r}
write.csv(diamonds, "data/diamonds.csv", quote = FALSE, row.names = FALSE)
chunk_rw("data/diamonds.csv", "data/diamonds.sqlite", "diamonds")
```

另一种极端的情况是，我们需要从很多个小文件中读取数据。这种情况下，我们把分布在所有文件中的数据写入一个数据库，以便轻松地实现查询。下列函数用来将一个文件夹中的所有 csv 文件数据放入一个数据库中：

```{r}
batch_rw <- function(dir, output, table, overwrite = TRUE) {
  files <- list.files(dir, "\\.csv$", full.names = TRUE)
  con <- dbConnect(SQLite(), output)
  on.exit(dbDisconnect(con))
  exist <- dbExistsTable(con, table)
  if (exist) {
      if (overwrite) dbRemoveTable(con, table)
      else stop(sprintf("Table '%s' already exists", table))
  }
exist <- FALSE
for (file in files) {
  cat(file, "... ")
  df <- read.csv(file, header = TRUE,
                stringsAsFactors = FALSE)
  dbWriteTable(con, table, df, row.names = FALSE,
              append = exist)
  exist <- TRUE
  cat("done\n")}
}
```

为了演示，我们在 data/groups 中放入多个小 csv 格式文件，使用 batch_rw( ) 将所有数据写入数据库。

```{r,eval=F}
batch_rw("data/groups", "data/groups.sqlite", "groups")
## data/groups/group1.csv ... done
## data/groups/group2.csv ... done
## data/groups/group3.csv ... done
```

现在，所有文件中的数据都被放入数据库了。我们可以读取整个表来看看最终效果:

```{r,eval=F}
con <- dbConnect(SQLite(), "data/groups.sqlite")
dbReadTable(con, "groups")
## group id grade
## 1 1 I-1 A
## 2 1 I-2 B
## 3 1 I-3 A
## 4 2 II-1 C
## 5 2 II-2 C
## 6 3 III-1 B
## 7 3 III-2 B
## 8 3 III-3 A
## 9 3 III-4 C
dbDisconnect(con)
## [1] TRUE
```

在此节中，你学习了 SQLite 数据库的基本知识和用法。实际上盛行的许多关系型数据库，与之功能、用法都很相近。掌握这些知识，足够你使用各种工具操作不同的关系型数据库，如用 RMySQL 操控 MySQL，用 RPostges 操控 PostreSQL，用 RSQLServer 操控 Microsoft SQL，用 RODBC 操控 ODBC 兼容数据库（Microsoft Acess 和 Excel）。它们具有几乎相同的功能，如果你熟悉其中之一，理应能顺利掌握其它数据库的用法。

##11.2操控非关系型数据库

在本章的前面几节中，你已掌握关系型数据库的基础，学会使用 SQL 语言查询数据。关系型数据库几乎是以表的形式组织的，即它是互有关系连接的表的集合。

然而，当数据的总量超出一个的服务器的容量时，新问题产生了，传统关系型数据库模型无法支持其水平可扩缩性要求，即，不再用单一服务器，而是用一组服务器存储数据。要使实际上以分散形式存储的数据，仍可以通过一个逻辑数据库的形式被访问，这就为数据库管理增加了一个层面的复杂性。

近些年来，NoSQL，非关系型数据库，得益于新数据库模型的引入和其在大数据分析和实时处理应用中的出色表现，开始流行起来。一些非关系型数据库设计旨在实现强有效性、强扩缩性、强灵活性和高性能。

关系型数据库和非关系型数据库在存储模型方面的差别是显而易见的。举例而言，对一个购物网站来说，商品和评论信息可以存储在一个具有两张表的关系型数据库里：商品表和评论表。所有的商品信息存储于一表中，各个商品的所有评价均存储于另一表中。以下代码展示了这些表的基本结构：

```
products:
code,name,type,price,amount
A0000001,Product-A,Type-I,29.5,500
```

每条评论带有一个字段，指向它描述的商品：

```
comments:
code,user,score,text
A0000001,david,8,"This is a good product"
A0000001,jenny,5,"Just so so"
```

当一个产品具有许多相关的表和海量的记录时，数据库必须分配给一组服务器，这会增加数据查询的难度，因为即使仅运行一个简单查询，也是极度低效的。如果我们用 MongoDB 来存储数据，每个商品被存储为一个文档，该商品的所有评论，以数组的形式存储在该文档的一个字段中。如此，数据查询就容易多了，实现多服务器分布式存储也更容易了。

这里以集合中一个商品的 JSON 文档为代表：

```
{
  "code":"A0000001",
  "name":"Product-A",
  "type":"Type-I",
  "price":29.5,
  "amount":500,
  "comments":[
    {
    "user":"david",
    "score":8,
    "text":"This is a good product"
    },
    {
    "user":"jenny",
    "score":5,
    "text":"Just so so"
    }
  ]
}
```

关系型数据库可能具有许多模式。每种模式（数据库）由多张表组成。每张表含有多条记录。相似的，一个 MongoDB 实体中能群集多个数据库。每个数据库中存在多个集合。每个集合内有多个文档。主要的区别在于，关系型数据库中，一张表的所有记录应具有相同的结构，但 MongoDB 数据库某集合内的文档却不受模式限制，可以灵活实现嵌套结构。

比如，前述的 JSON 代码，一种商品由这样一个文档来描述，文档内， code、name、type、price 和 amount 为简单数据类型，而 comment 则是数组对象。每条评论由 comment 数组的一个元素代表，且由 user、score、text 三部分结构组成。该商品的所有评论共同组成一个对象存储于 comments 字段中。因此，考虑产品信息和评论，每个商品都是独立自足的。如果我们需要某个产品的信息，我们不再需要连接两张表，而只要选出几个字段。

欲安装 MongoDB，访问 https://docs.mongodb.com/manual/installation/ 遵说明操作。它支持几乎所有主流平台。

###11.2.1操控 MongoDB 数据库
####1.用 MongoDB 查询数据

假设我们要在本地设备上运行 MongoDB 实体。我们使用 mongolite 程序包操控 MongoDB。安装该程序包可运行以下代码：

```{r,eval=F}
install.packages("mongolite")
```

一旦安装好程序包，我们可以通过声明集合、数据库和 MongoDB 的地址来创建 Mongo 连接：

```{r,warning=F}
library(mongolite)
m <- mongo("products", "test", "mongodb://localhost")
```

首先，我们创建一个连接，连接至本地的 MongoDB 实体。初始状态下，集合 products 不含任何文档。

```{r}
m$count( )
```

欲往数据库增添一个含评论的产品，可以直接将 JSON 文档以字符串形式输入 m$insert( )：

```{r,results='hide'}
m$insert('
{
  "code": "A0000001",
  "name": "Product-A",
  "type": "Type-I",
  "price": 29.5,
  "amount": 500,
  "comments": [
    {
    "user": "david",
    "score": 8,
    "text": "This is a good product"
    },
    {
    "user": "jenny",
    "score": 5,
    "text": "Just so so"
    }
  ]
}')
```

现在，这个集合中就有一个文档了：

```{r}
m$count( )
```

另一种方法是，借用 R 中的列表对象来表示相同的结构。以下代码使用 list( ) 方法增添了第二个产品：

```{r,results='hide'}
m$insert(list(
  code = "A0000002",
  name = "Product-B",
  type = "Type-II",
  price = 59.9,
  amount = 200L,
  comments = list(
    list(user = "tom", score = 6L,
        text = "Just fine"),
    list(user = "mike", score = 9L,
        text = "great product!")
  )
), auto_unbox = TRUE)
```

注意，R 并没有提供标量类型，所以默认情况下，所有向量在 MongoDB 中都会被理解成 JSON 数组，除非 auto_unbox = TRUE，它会使单元素向量转化为 JSON 中的标量。
如果没有设置 auto_unbox = TRUE，你应该用 jsonlite::unbox( ) 来确保标量输出或用 I( ) 确保数组输出。

现在，集合中有两个文档了：

```{r}
m$count( )
```

接着，我们用 m$find( ) 来取出集合中的所有文档，出于可操控性，结果将会自动简化为数据框形式。

```{r}
products <- m$find( )
str(products)
```

为了避免自动转化，我们可以用 m$iterate( ) 在集合中进行迭代，并得到具备原始存储形式的列表对象。

```{r}
iter <- m$iterate( )
products <- iter$batch(2)
str(products)
```

欲对集合进行筛选，我们可以在 m$find( ) 中声明条件查询及字段：

首先，我们查询 code 为 A0000001 的文档并取出其 name、price、amount 字段：

```{r}
m$find('{ "code": "A0000001" }',
'{ "_id": 0, "name": 1, "price": 1, "amount": 1 }')
```

接着，我们查询 price 字段大于等于40的文档，这一步通过条件查询的 $gte 算子实现：

```{r}
m$find('{ "price": { "$gte": 40 } }',
'{ "_id": 0, "name": 1, "price": 1, "amount": 1 }')
```

我们不仅能在文档字段中进行查询，也可以在数组字段中查询某对象。下列代码用来取出评论数组中有9分评论的商品文档：

```{r}
m$find('{ "comments.score": 9 }',
'{ "_id": 0, "code": 1, "name": 1}')
```

类似地，下面的代码可取出带有6分以下低分评论的商品文档：

```{r}
m$find('{ "comments.score": { "$lt": 6 }}',
'{ "_id": 0, "code": 1, "name": 1}')
```

注意，使用 . 记号可以轻松实现对子文档中字段的访问，这使我们更加灵活地对嵌套结构进行控制：

```
##TRUE
```

m$insert( ) 函数也可以用来处理 R 中的数据框。现在，我们将创建一个新的 MongoDB 连接使之连接至另一集合：

```{r}
m <- mongo("students", "test", "mongodb://localhost")
```

我们会创建一个 MongoDB 连接对象 m，指向本地 MongoDB 实体 test 数据库的 students 集合。

```{r}
m$count( )
```

最初这个集合中没有文档。我们创建一个简单的数据框，以便往里增添一些数据：

```{r}
students <- data.frame(
  name = c("David", "Jenny", "Sara", "John"),
  age = c(25, 23, 26, 23),
  major = c("Statistics", "Physics", "Computer Science", "Statistics"),
  projects = c(2, 1, 3, 1),
  stringsAsFactors = FALSE
)
students
```

接着我们以每行为一个文档添入集合中：

```{r,results='hide'}
m$insert(students)
```
```
##
Complete! Processed total of 4 rows.
```

现在，集合中有一些文档了：

```{r}
m$count( )
```

我们可以用 find( ) 取出所有的文档：

```{r}
m$find( )
```

如上一个例子中我们提到的，文档被存储在 MongoDB 集合中的方式，与关系型数据库中字段存储在表中的形式大有不同。MongoDB 集合中的一个文档，更像是一个 JSON 文档，但实际上，它是以二进制数据形式存储的，以达到其高性能表现和强紧凑性。m$find( ) 函数首先取出类 JSON 表格中的数据，然后将它简化成操作性较强的数据格式。

为了筛选数据，我们可以在 m$find( ) 中声明条件查询。例如，我们想找出全名为 Jenny 的所有文档：

```{r}
m$find('{ "name": "Jenny" }')
```

结果自动转化为数据框格式，以便于我们使用。接着，我们会查询 projects 字段数值大于等于2的所有文档：

```{r}
m$find('{ "projects": { "$gte": 2 }}')
```

为选择字段，我们设置 find( ) 函数的 fields 参数：

```{r}
m$find('{ "projects": { "$gte": 2 }}',
'{ "_id": 0, "name": 1, "major": 1 }')
```

我们也可以设置 sort 参数整理数据：

```{r}
m$find('{ "projects": { "$gte": 2 }}',
fields ='{ "_id": 0, "name": 1, "age": 1 }',
sort ='{ "age": -1 }')
```

限制返回文档的数量，用 limit 参数：

```{r}
m$find('{ "projects": { "$gte": 2 }}',
fields ='{ "_id": 0, "name": 1, "age": 1 }',
sort ='{ "age": -1 }',
limit =1)
```

同时，我们可以得到所有文档中某一字段的不重复取值：

```{r}
m$distinct("major")
```

我们可以为不重复值的检索添加一个条件：

```{r}
m$distinct("major", '{ "projects": { "$gte": 2 } }')
```

要更新某个文档，我们可以调用 update( )，找到所选文档，设置某些字段的取值：

```{r}
m$update('{ "name": "Jenny" }', '{ "$set": { "age": 24 } }')
m$find()
```

####2.创建或移除索引

同关系型数据，MongoDB 也支持索引。每个集合都可以有多个索引，索引字段会被贮藏在内存中，以便快速查找。合理创建索引能够使文档检索工作变得非常高效。

借助 mongolite 程序包能够轻松在 MongoDB 中创建索引。这个工作在我们输入数据前或输入数据后进行都是可行的。然而，如果我们已经输入了大量数据，这时候创建索引的工作是非常费时的。如果我们在导入任何文档前就创建了太多索引，则会增加导入文档工作过程中的麻烦。

这里，我们为 students 集合创建一个索引：

```{r}
m$index('{ "name": 1 }')
```

现在，如果我们想要通过索引字段查找一个文档，其运算性能是优异的：

```{r}
m$find('{ "name": "Sara" }')
```

如果没有文档满足条件，则会返回一个空数据框：

```{r}
m$find('{ "name": "Jane" }')
```

最后，使用 drop( ) 删除集合。
```{r}
m$drop( )
```

显然，如果数据量本身很小，那么由索引带来的性能提升是很有限的。在下一个例子中，我们会创建行数更多的一个数据框，以便比较使用索引和不使用索引情况下，查找文档的性能差异。

```{r}
set.seed(123)
m <- mongo("simulation", "test")
  sim_data <- expand.grid(
  type = c("A", "B", "C", "D", "E"),
  category = c("P-1", "P-2", "P-3"),
  group = 1:20000,
  stringsAsFactors = FALSE)
head(sim_data)
```

索引字段已经创建好了。接下来，我们需要生成一些随机数字：

```{r}
sim_data$score1 <- rnorm(nrow(sim_data), 10, 3)
sim_data$test1 <- rbinom(nrow(sim_data), 100, 0.8)
```

现在数据框状态如下：

```{r}
head(sim_data)
```

接着，我们会增添一些数据到 simulation 集合中：

```{r,results='hide'}
m$insert(sim_data)
```
```
Complete! Processed total of 300000 rows.
[1] TRUE
```
第一项测试，未使用索引情况下查询一个文档耗时多长：

```{r,results='hide'}
system.time(rec <- m$find('
        { "type": "C", "category": "P-3", "group": 87}'))
```
```
##
Found 1 records...
Imported 1 records. Simplifying into dataframe...
## user system elapsed
## 0.000 0.000 0.104
rec
##    type category group score1 test1
## 1   C    P-3     87    6.556688 72
```

第二项测试，使用联合条件查询文档的性能表现：

```{r,results='hide'}
system.time({
  recs <- m$find('{ "type": { "$in": ["B", "D"] },
                  "category": { "$in": ["P-1", "P-2"] },
                  "group": { "$gte": 25, "$lte": 75 } }')
  })
```
```
##
Found 204 records...
Imported 204 records. Simplifying into dataframe...
## user system elapsed
## 0.004 0.000 0.094
```

接着，查询结果数据框如下：

```{r}
head(recs)
```

第三项测试，使用非索引字段进行文档查询的性能表现：

```{r,results='hide'}
system.time(recs2 <- m$find('{ "score1": { "$gte": 20 } }'))
```
```
##
Found 158 records...
Imported 158 records. Simplifying into dataframe...
## user system elapsed
## 0.000 0.000 0.096
```

查询结果数据框如下：

```{r}
head(recs2)
```

以上三个测试都在无索引的情况下完成。为了做个对比，现在我们创建一个索引：

```{r}
m$index('{ "type": 1, "category": 1, "group": 1 }')
```

一旦索引创建，第一项测试，以索引字段进行查询，就变得非常快捷：

```{r,results='hide'}
system.time({
        rec <- m$find('{ "type": "C", "category": "P-3", "group": 87 }')
})
```
```
##
Found 1 records...
Imported 1 records. Simplifying into dataframe...
## user system elapsed
## 0.000 0.000 0.001
```

第二项测试结果也很快输出：

```{r,results='hide'}
system.time({
            recs <- m$find('{ "type": { "$in": ["B", "D"] },
            "category": { "$in": ["P-1", "P-2"] },
            "group": { "$gte": 25, "$lte": 75 } }')
})
```
```
##
Found 204 records...
Imported 204 records. Simplifying into dataframe...
## user system elapsed
## 0.000 0.000 0.002
```

然而，非索引字段的查询性能却没有提到提升：

```{r,results='hide'}
system.time({
recs2 <- m$find('{ "score1": { "$gte": 20 } }')
})
```
```
##
Found 158 records...
Imported 158 records. Simplifying into dataframe...
## user system elapsed
## 0.000 0.000 0.095
```

MongoDB 另一个重要特性在于它的聚合管道。当我们聚集数据时，我们其实是进行了大批的聚合运算，使得它们被组织到 MongoDB 实体中。例如，下面的例子将数据依照 type 字段分组。每一组中有计数字段、平均分、最小测试分和最大测试分。由于输出冗长，这里我们不将它打印输出。你可能会想自行运行下列代码查看结果：

```
m$aggregate('[
  { "$group": {
    "_id": "$type",
    "count": { "$sum": 1 },
    "avg_score": { "$avg": "$score1" },
    "min_test": { "$min": "$test1" },
    "max_test": { "$max": "$test1" }
    }
  }
]')
```

我们也可以将多个字段作为一个组的键，这与 SQL 中的语句 group by A,B 类似：

```
m$aggregate('[
  { "$group": {
    "_id": { "type": "$type", "category": "$category" },
    "count": { "$sum": 1 },
    "avg_score": { "$avg": "$score1" },
    "min_test": { "$min": "$test1" },
    "max_test": { "$max": "$test1" }
    }
  }
]')
```
聚合管道支持聚合运算的高效运作：

```
m$aggregate('[
  { "$group": {
    "_id": { "type": "$type", "category": "$category" },
    "count": { "$sum": 1 },
    "avg_score": { "$avg": "$score1" },
    "min_test": { "$min": "$test1" },
    "max_test": { "$max": "$test1" }
    }
  },
  {
  "$sort": { "_id.type": 1, "avg_score": -1 }
  }
]')
```
我们可以通过增加更多运算操作，来延长管道。比如，以下例子用于创建组、聚合数据。接着，它会计算平均分值，并按降序顺序整理文档，提取出平均值最大的三组文档，并将有用字段进行投影。

```
m$aggregate('[
  { "$group": {
    "_id": { "type": "$type", "category": "$category" },
    "count": { "$sum": 1 },
    "avg_score": { "$avg": "$score1" },
    "min_test": { "$min": "$test1" },
    "max_test": { "$max": "$test1" }
    }
  },
  {
    "$sort": { "avg_score": -1 }
  },
  {
    "$limit": 3
  },
  {
    "$project": {
    "_id.type": 1,
    "_id.category": 1,
    "avg_score": 1,
    "test_range": { "$subtract": ["$max_test", "$min_test"] }
    }
  }
]')
```

除了我们在例子中演示的聚合运算，还有许多强大的运算。更多细节，请访问 https://docs.mongodb.com/manual/reference/operator/aggregation-pipeline/ 和 https://docs.mongodb.com/manual/reference/operator/aggregation-arithmetic/。

MongoDB的又一重要特性，是它内部支持 MapReduce（https://en.wikipedia.org/wiki/MapReduce）。MapReduce 模型在分布式集群的大数据分析中运用广泛。在我们的环境下，我们可以写一个极度简单的 MapReduce 代码，试着生成一些数据的直方图：

```
bins <- m$mapreduce(
  map = 'function() {
    emit(Math.floor(this.score1 / 2.5) * 2.5, 1);
    }',
  reduce = 'function(id, counts) {
    return Array.sum(counts);
    }'
)
```

MapReduce 的第一步就是映射。在这一步骤，所有数值被映射至一个关键值对。接着，简约步骤，会聚合关键值对。在前面的例子中，我们简单计算了每一个区间（bin）的记录数：

```
bins
## _id value
## 1 -5.0 6
## 2 -2.5 126
## 3 0.0 1747
## 4 2.5 12476
## 5 5.0 46248
## 6 7.5 89086
## 7 10.0 89489
## 8 12.5 46357
## 9 15.0 12603
## 10 17.5 1704
## 11 20.0 153
## 12 22.5 5
```

我们也可以由 bins 创建一张条形图：

```
with(bins, barplot(value /sum(value), names.arg = `_id`,
main = "Histogram of scores",
xlab = "score1", ylab = "Percentage"))
```

生成的条形图如下：

![alt text](C:\Users\River\Desktop\2016年研一上\数据分析\翻译任务\picture.png)

如果该集合不再有用处了，那么我们可以用 drop( ) 函数删除它：

```{r}
m$drop( )
```

因为这一节仅停留在介绍层面，MongoDB 的更多高级操作远远超出该书的范围。如果你对 MongoDB 有兴趣，请浏览官方指南 https://docs.mongodb.com/manual/tutorial/。

###11.2.2使用 Redis

Redis（https://redis.io/）,既不像 SQLite 那样以表形式存储数据，也不像 MongoDB 那样允许以嵌套结构存储和进行查询，它是一种内存缓存数据结构的存储方法。它会将键-值（key-value）缓存于内存中，借此达到极高的键值检索能力。然而，它并不支持 SQL 数据库或 MongoDB 中所使用的查询语言。

Redis通常被用作高速缓冲存储器。我们可以用它存储、操作一系列基本的数据结构。安装 Redis，访问 https://redis.io/download。不幸的是，官方版本不支持 Windows 操作系统，但 Microsoft Open Tech 小组开发并维护着一版 Win64 接口的 Redis，获取请访问 https://github.com/MSOpenTech/redis。

SQL 数据库存储表格、MongoDB 存储文档，而 Redis 存储键-值对，如下：

```
name: Something
type: 1
grade: A
```

该值可以具有更复杂的数据结构（例如，哈希映射、集合、有序集合）而非仅仅是简单数值，Redis 提供了一个能够高效低延迟地处理这类数据的简单界面。

####1.用 R 访问 Redis

从 R 访问 Redis 实体，需要使用 rredis 程序包，它提供了一些操控 Redis 的简单函数。安装此程序包，需运行下列代码：

```
install.packages("rredis")
```

一旦程序包准备就绪，我们就可连接至 Redis 实体:

```{r,warning=F}
library(rredis)
redisConnect( )
```

不设置参数的情况下，它会默认连接至本地 Redis 实体。我们也可以连接至远程实体。

####2.设置 Redis 服务器和数据获取

使用 Redis 的最基本方法就是调用 redisSet(key, value)。在 R 中，这个值默认序列化，因此我们可以将任何 R 对象存储至 Redis:

```{r}
redisSet("num1", 100)
```

现在，该命令生效了，我们可以取出同个键中的值：

```{r}
redisGet("num1")
```

我们可以存储一个整数向量：

```{r}
redisSet("vec1", 1:5)
redisGet("vec1")
```

甚至可以存储一个数据框：

```{r,echo=F}
data(mtcars)
```

```{r}
redisSet("mtcars_head", head(mtcars, 3))
redisGet("mtcars_head")
```

实际上，如果其它的计算机有权限访问你的 Redis 实体，他们在 R 中用 redisGet( ) 会得到一样的数据。

然而，如果这个键根本不存在，我们只能得到 NULL：

```{r}
redisGet("something")
```

我们可以用 redisExists( ) 来检验某个键是否存在，而不是如上例般得到 NULL。

```{r}
redisExists("something")
redisExists("num1")
```

如果我们不再用到某个键，可以用 redisDelete( ) 删除它：

```{r}
redisDelete("num1")
redisExists("num1")
```

除了单纯的键-值对，Redis 也支持一些更高级的数据结构。比如，我们可以用 redisHset( ) 创建哈希映射，这里举一个水果映射的例子，不同的水果具有不同数字：

```{r}
redisHSet("fruits", "apple", 5)
redisHSet("fruits", "pear", 2)
redisHSet("fruits", "banana", 9)
```

我们可以调用 redisHGet( ) 来获取哈希映射中某个字段的值：

```{r}
redisHGet("fruits", "banana")
```

我们也可以用列表对象来代表这个哈希映射的结构：

```{r}
redisHGetAll("fruits")
```

另外，我们可以得到哈希映射的键：

```{r}
redisHKeys("fruits")
```

我们也可以仅取出哈希映射中的所有值（不取出键）：

```{r}
redisHVals("fruits")
```

另外，我们很容易得到哈希映射中的字段数：

```{r}
redisHLen("fruits")
```

也可以一次性取出多个字段的值：

```{r}
redisHMGet("fruits", c("apple", "banana"))
```

还可以通过输入一个列表对象，来设置多个字段的值：

```{r}
redisHMSet("fruits", list(apple = 4, pear = 1))
```

现在，字段中的值被更改了：

```{r}
redisHGetAll("fruits")
```

除了哈希映射，Redis 同时支持队列。我们可以从队列的左端或右端输入值。例如，我们从右端依次输入整数1、2、3：

```{r}
for (qi in 1:3) {
  redisRPush("queue", qi)
}
```

调用 redisLLen( ) 获取当前队列长度：

```{r}
redisLLen("queue")
```

现在，这个队列有三个元素。注意这里的值是一个字符向量，而不是整型数值。因此，如果在其它情境中我们需要使用数值形式，就必须进行转化：

接着，我们从左端提取队列中的值：

```{r}
redisLPop("queue")
redisLPop("queue")
redisLPop("queue")
redisLPop("queue")
```

注意队列中只有三个元素供我们取出，第四次试图提取的动作得到返回值 NULL，这可以用来检查队列当前是否为空。

最后，我们应关闭指向 Redis 的连接，释放占用资源。

```{r}
redisClose()
```

Redis 具有更多高级的性能，远超出本章所讲的范围。它不仅支持数据结构存储，还可用于消息代理，即，我们可以利用它在不同程序间传送消息。更多高级用法，可访问 http://redis.io/documentation 阅读官方文档。

##11.3总结

本章中，你学习了如何用 R 访问几种不同类型的数据库。我们介绍了以 SQLite 为代表的关系型数据库、以 MongoDB 和 Redis 为代表的非关系型数据，及其基本用法。在理解它们功能和特性的差异后，我们应学会在项目工作中，根据我们的目的和需求，选择合适的数据库。

在许多数据相关的项目中，数据存储和数据输入仅仅是最初的步骤，而数据清洗和数据处理往往最为耗时。在下一章中，我们将开始学习数据处理技术。你会学习到几个专门用于数据处理的程序包，它们简明而功能强大。为了更好地使用这些程序包，我们需要深入理解它们是如何运作的，因此需要系统性掌握我们前面几章所介绍的知识。