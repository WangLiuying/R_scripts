---
title: "鏌愭煇鐧剧"
author: "Wang, Liuying"
date: "2017骞<b4>7鏈<88>31鏃<a5>"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##广义交叉验证

在非线性模型拟合中，通常需要权衡基函数的个数，因此，正则化参数影响着拟合模型的光滑程度。

$$\hat g_{n,\lambda}=\text{argmin}_{\hat g_i\in W_2^{(m)}}\sum_{i=1}^n(y_i-\hat g(t_i))^2+\lambda\int_0^1(\hat g^{(m)}(t))^2dt \quad \lambda\ge0$$

$\hat g_{n,\lambda}$ 是拟合的模型，其中 $\lambda$ 系数关系着选择的基函数种类，$\lambda=0$ ，$\hat g_{n,\lambda}$ 是插值样条；$\lambda =\infty$ ，$\hat g_{n,\lambda}$ 是 m-1 次多项式； $0<\lambda<\infty$ ， $\hat g_{n,\lambda}$ 可选用自然样条。

因此， $\lambda$ 的选择决定基函数的选择，由此影响模型整体的拟合效果。一般来说，选择使得MSE最小的 $\lambda$ :

$$\lambda^*=\text{argmin}_{\lambda\in R^+}R(\lambda)=\text{argmin}_{\lambda\in R^+}\frac{1}{n}\sum_{i=1}^n(\hat g_{n,\lambda}(t_i)-g_{t_i})^2$$
在OCV（Ordinary Cross-Validation）中，令

$$\hat g^{(k)}_{n,\lambda}=\text{argmin}_{\hat g_i \in W_2^{(m)}}\sum_{i\ne k}(y_i-\hat g(t_i))^2+\lambda\int_0^1(\hat g^{(m)}(t))^2dt\quad \lambda\ge0$$
OCV-MSE为 $V_0(\lambda)=\frac{1}{n}\sum_{i=1}^n(\hat g^{(i)}_{n,\lambda}(t_i)-y_i)^2$ ,并选择 $\lambda_0=\text{argmin}_{\lambda\in R^+}V_0(\lambda)$


OCV的思路是，固定一个 $\lambda$ ,对i=1,2,...,n，在预测第i个点时，使用余下的(n-1)个点进行拟合、预测，用n次预测的拟合值计算MSE，并选择令OCV最小的 $\lambda$

OCV存在的问题是，所有的样本点都被“平等地”对待，它实际上假设了数据不具有周期性，且样本点自变量之间是等距的。

为了调节样本点的权重，改进OCV（得到GCV），使其在处理周期性和非等距样本时具有同样优良的表现，考虑以下程序：

1. 找到 $n \times n$ 影响矩阵 $A(\lambda)$ ,使其具有性质：
$$\begin{bmatrix} \hat g_{n,\lambda}(t_1) \\ \hat g_{n,\lambda}(t_2) \\ \vdots \\ \hat g_{n,\lambda}(\lambda_n) \end{bmatrix} =A(\lambda)y$$
则 $V_0(\lambda)$ 可以重写为：

$$V_0(\lambda)=\frac{1}{n}\sum_{k=1}{n}\frac{\sum_{i=1}^n(a_{kj}y_j-y_k)^2}{(1-a_{kk})^2}$$
其中， $a_{kj}$ 是 $A(\lambda)$ 第k行第j列的元素。

进一步的，GCV可以重写为:

$$V(\lambda)=\frac{1}{n}\sum_{i=1}^n(\hat g^{(i)}_{n,\lambda}(t_i)-y_i)w_k(\lambda)$$
即对OCV中的每个样本点的离差平方进行加权平均，其中，权重为：

$$w_k(\lambda)=(\frac{1-a_{kk}(\lambda)}{\frac{1}{n}tr(I-A(\lambda))})^2$$
余下的求解过程与OCV相同，GCV的收敛性质可参考论文：Smoothing Noisy Data with Spline Function (1979) - Peter Craven, Grace Wahba；Optimal Estimation of Contour Properties by Cross-Validated Regularization (1989) - Behzad Shahraray, David Anderson。


##信仰分布

基于信仰的推断，是统计推断方法之一。现代统计实践中，信仰推断虽不如频率推断、贝叶斯推断和决策论等流行，但信仰推断在统计学历史中具有重要的地位，基于它的研究同时推进了理论统计学中许多概念和工具的发展。不少现有的统计学方法论研究与信仰推断密切相关。

####信仰分布的提出背景
信仰推断的一般方法是由Ronald Fisher提出的。信仰推断的思想是在不使用先验概率分布的前提下尝试计算逆概率。在频率推断中，置信区间的置信度水平 $\alpha$ 表示，通过100次重抽样计算出的置信区间中约有 $100\alpha$ 次包含真值，但实际操作中对一个样本我们仅能得到一个置信区间。至于贝叶斯推断中的可信区间，由于我们总是在计算“已知信息下真实值的条件概率分布”，对每一个可信区间我们都可以给出其包含真值的概率。相似地，Fisher提出信仰推断的目的在于，基于观测数据，对推断结论计算一个“逆概率”。具体方法是，通过推导“信仰分布”，给定任意一组未知参数的取值，测量可信度。

####信仰分布

为了应用信仰推断方法，Fisher要求分布的充分统计量存在。假设单参数情况下，存在一个充分统计量，即给定该充分统计量，数据的条件分布不依赖于该参数。举例而言：

若n个独立观测值服从 $U[0,\omega]$，最大观测值 $X_{(n)}$ 是参数 $\omega$ 的充分统计量，假设现在仅有 $X_{(n)}$ 被记录了下来，其它数据遗失。那么，其它数据的条件分布正是 $U[0,X_{(n)}]$ ,不再依赖于原参数 $\omega$ 。并且 $X_{(n)}$ 已经给出了该数据中所有的有效信息。

可以推导出，$X_{(n)}$ 的CDF为：

$$F(x)=P(X_{(n)}\le x)=P(\text{all observations}\le x)=(\frac{x}{\omega})^n$$

因此给定一个 $X/\omega$ 即可得相应的概率推断。

令$(\frac{x}{\omega})=a,x=a\omega$
则$$P(x< X_{(n)})=P(a\omega < X_{(n)}))=P(\omega<\frac{X_{(n)}}{a})=1-a^n$$

如上推导出的 $\omega$ 的分布称为信仰分布。

这个方法的关键在于构建一个随机变量(例中的a)，它是观测值和参数的函数，同时它的概率分布不依赖于参数。这一随机变量被称为枢轴量。注意这种方法仅当充分统计量存在时奏效。

####后续发展

信仰推断一经问世就饱受争议，有学者提出了该方法的矛盾之处，就连Fisher本人也承认该推断方法仍有一些问题。直到今日，坚持对信仰推断方法的研究仍不断给人们带来新的启发。


##分布族

分布族，顾名思义，即一族概率分布模型。

统计研究中，常常需要假设随机样本 $X^n=(X_1,X_2,...,X_n)$ 来自某一类总体分布 $f_X(x;\theta)$ , $f_X(x,\theta)$ ,其中 $\theta$ 是未知参数。如此， 即确定了一个统计问题的样本分布族，确定了样本分布族即确定了该问题的统计模型。

样本分布族可以分为两类，如果样本分布族值含有有限个（未知）参数，则此分布族为参数分布族，凡是不属于这种情况的分布族为非参数分布族。通常，我们所说的分布族，指的是狭义的“参数分布族”。

####参数分布族

考察一族参数候选分布 $$\mathit{F}=\{f(.,\theta):\theta \in \Theta\}$$
其中 $f:\Omega \times \Theta \rightarrow R^+$ 是已知的PMF或PDF函数，$\Omega$ 是随机变量 $X_i$ 的支撑，$\Theta$ 是p维参数向量 $\theta$ 的参数空间，其中p维有限且固定的常数，$\theta\in \Theta$ 的每一个值都对应了 $f_X(x)$ 的一个分布模型。

若函数族 $\mathit{F}$ 包含了生成观测数据的真实总体分布 $f_X(.)$ 则称模型 $\mathit{F}$ 族正确设定了总体分布 $f_X(.)$ ,反之则称 $\mathit{F}$ 族是总体分布 $f_X(.)$ 的误设。例如，若设定一正态分布模型族，但真实总体服从伽玛分布，即为误设。

####分布族与参数方法

样本被视为从分布族的某个参数族抽取出来的总体的代表，而未知的仅仅是总体分布具体的参数值。推断问题就转化为对分布族的若干个未知参数的估计问题。用样本对这些参数做出估计或者进行某种形式的假设检验，这类推断方法称为参数方法。

##指数型分布族 

务必与指数分布（exponential distribution）区分。

指数型分布族（exponential family）是由具有某一特定形式的概率分布组成的集合。指数型分布族具有一些代数计算上的优良性质。该概念在1935-36年由E. J. G. Pitman,G. Darmois,和B. O. Koopman提出。

####指数型分布族的特定形式

其总体PMF/PDF可表示为：
$$ f_X(x|\theta)=h(x)g(\theta)exp({\eta(\theta)}^{T}T(x))$$
式中，$T(.),h(.),\eta(.)$ 是已知函数， $\theta$ 是参数向量。

若 $\eta(\theta)=\theta$ ，则称为具有正则形式。通过合理定义 $\eta(.)$ ，总能将指数型分布族转化为正则形式。

如果 $\theta$ 的维数小于 $\eta(\theta)$, 则该概率分布属于曲线指数族。注意，指数型分布族中的绝大多数常见部分不属于曲线指数族，且多数针对指数分布族设计的算法假设分布“非曲”。

指数型分布族的重要特征是，其参数和变量观测值可以被分离至不同的因子中。


指数型分布族囊括了许多常见的分布：

正态分布、指数分布、伽玛分布、卡方分布、贝塔分布、狄利克雷分布、伯努利分布、类别分布、泊松分布、Wishart分布与逆Wishart分布。

还有一些常见分布，仅当部分参数固定且已知时，具有指数型分布形式：


* 二项分布（重复次数n固定时）
* 多项分布（重复次数n固定时）
* 负二项分布（失败次数固定时）

不属于指数分布族的例子有：
学生t分布、绝大多数混合分布。

####因子解释

在以上定义中，函数 $T(x),\eta(\theta)$ 是任意的，然而这些函数对解释这一分布族有着重要的意义。

- $T(x)$ 是该分布的一个充分统计量。充分统计量是观测数据的函数，能够完全总结数据 $x$ 的密度函数的信息。$T(x)$ 的维度与参数 $\theta$ 的维度相同。一组独立同分布变量观测值的充分统计量即每个变量充分统计量的简单加和，并且包含了后验分布的所有信息。

- $\eta$ 称为自然参数。对于给定的分布函数 $f_X(x;\theta)$ ，$\eta$ 的取值空间称为自然参数空间。

####性质

指数型分布族具有许多优良性质，使其在统计分析中非常有用。可以证明，只有指数型分布族具有以下性质：

- 只有指数型分布族，可以用固定数量的充分统计量来总结任意个独立同分布变量。

- 指数型分布族具有共轭先验分布，在贝叶斯统计中这是非常重要的性质。

- 对于具有共轭先验分布的指数型分布随机变量，其后验预测分布可用解析式表达（注意并非只有指数型分布具有该性质，t分布、贝塔-二项分布和狄利克雷-多项分布也具有类似性质）。

####统计学应用场景

指数型分布及其性质主要常见于以下场景：

- 充分统计量。根据Pitman-Koopman-Darmois定理，给定参数的定义域，只有指数型分布族，在样本容量增大时，其充分统计量的维数保持有限。

- 贝叶斯参数估计：共轭分布。在贝叶斯统计中，用先验概率分布乘以似然函数并进行正态化，可以得到后验分布。若似然函数和先验分布互为共轭分布，则后验分布形式与先验保持一致。其中先验分布常属指数型分布族。

- 假设检验：一致最大功效检验。若 $\eta(\theta)$ 是非递减的，那么关于充分统计量 $T(x)$ 的似然比也是单调非递减的。因此，对于假设检验：$H_0:\theta \ge \theta_0$ 存在一致最大功效检验。

- 广义线性模型：指数型分布族常常被用作广义线性模型的基函数。

